{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SGAI_Explainer_notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "fvM9MeznY0_U",
        "Kf4nX63WVdeX"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMtvCWZRHtM8alUfvADQdWR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SimonTommerup/02805-sgai/blob/main/notebooks/thomas_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V06tNTDLiQ5Z"
      },
      "source": [
        "Imports used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRg0HIrTUQ6I",
        "outputId": "b3a16e9b-e74e-4f6f-bb0d-d7cba3d72499",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "\n",
        "from collections import Counter\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puF6ABWVUmRi"
      },
      "source": [
        "# 1 Motivation\n",
        "- What is your dataset?\n",
        "- Why did you choose this/these particular dataset(s)?\n",
        "- What was your goal for the end user's experience?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiZnKQFCb-t2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-HscjB8ZdiQ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NjyTiF0U3yz"
      },
      "source": [
        "# 2 Basic stats. Let's understand the dataset better\n",
        "- Write about your choices in data cleaning and preprocessing\n",
        "- Write a short section that discusses the dataset stats (here you can recycle the work you did for Project Assignment A) **But leave network stats (#nodes, #edges degree...) to next section!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08GSh1ZTdG0C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bq7UjHJdZdBW"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iz3xzEYPUpK-"
      },
      "source": [
        "# 3 Tools, theory and analysis. Describe the process of theory to insight\n",
        "In this section we analyze the above presented data using network science tools and data analysis strategies.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsWy83p_VnYu"
      },
      "source": [
        "## 3.1 Introducing the analysis\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhWRLgwsWBO2"
      },
      "source": [
        "\n",
        "As mentioned and discussed in previous sections, we will be investigating typical users on the subreddit pages of the two 2020 presidential candidates of USA [Trump](https://www.reddit.com/r/donaldtrump/) and [Biden](https://www.reddit.com/https://www.reddit.com/r/joebiden/).\n",
        "\n",
        "Initially we will **Introduction..., then 3.2 then 3.3. then 3.4. (overview!)**.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2loFQy-W5zC"
      },
      "source": [
        "### 3.1.2 The bipartite network **Consider: building actual bipartite network?**\n",
        "We will represent our data with a bipartite network of users and subreddits. For our data we have \n",
        "- $U$, the set of users\n",
        "- $S^u$, the set of subreddits which $u \\in U$ has commented on, excluding \n",
        "- $S$, the set of all subreddits commented on by all users.\n",
        "\n",
        "Note that we do not include [Trump](https://www.reddit.com/r/donaldtrump/) and [Biden](https://www.reddit.com/https://www.reddit.com/r/joebiden/) subreddits in $S^u$ and $S$\n",
        "\n",
        "We can assemble this data into a undirected bipartite network $G_{bi}$ with two distjoint sets of nodes $U$ and $S$. A user $u \\in U$ is connected to subreddit $s \\in S$ if $s \\in S^u$. This means that we have a network $G_{bi}$ where a user has a connection to all subreddits which it have commented on. And these subreddits are further connected to every other user, which has also commented on this subreddit. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BH9puB0KXVfT"
      },
      "source": [
        "### 3.1.3 Building a weighted network of users\n",
        "In order to apply a wide range of network science tools and data science strategies from 02805, a projection of $G_{bi}$ is considered, constituting a network of users. Specifically, a [simple projection](https://en.wikipedia.org/wiki/Bipartite_network_projection) is considered where users $u_i$ and $u_j$ are connected with weight equal to the size of $(S^{u_i}\\cap S^{u_j})$ - i.e. weight is equal to number of subreddits which both users has commented on. \n",
        "\n",
        "We will be using our constructed pandas dataframe to generate the weighted network $G$ implicit from $G_{bi}$, as it is more simple."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0lM03-j23k2"
      },
      "source": [
        "\n",
        "def get_ids_of_users_with_common_subreddits(user_id, users, used_subreddits):\n",
        "    users_with_common_subreddits = []\n",
        "    for other_user_id in range(len(users)):\n",
        "        if other_user_id != user_id:  # Skip connection to self\n",
        "            for subr in used_subreddits[user_id]:\n",
        "                if subr in used_subreddits[other_user_id]:\n",
        "                    users_with_common_subreddits.append(other_user_id)\n",
        "                    break\n",
        "    return users_with_common_subreddits\n",
        "\n",
        "\n",
        "def get_common_subreddits(user_id, other_user_id, used_subreddits):\n",
        "    common_subreddits = [subreddit for subreddit in used_subreddits[user_id] if subreddit in used_subreddits[other_user_id]]\n",
        "    return common_subreddits\n",
        "\n",
        "  \n",
        "def create_graph(users, used_subreddits, from_subreddits, n_required_subreddits=1):\n",
        "    G = nx.Graph()\n",
        "    # Loop through all users\n",
        "    for user_id in tqdm(range(len(users))):\n",
        "        # Add a node for EVERY user in data set \n",
        "        G.add_node(users[user_id], from_subreddit=from_subreddits[user_id])\n",
        "\n",
        "        # Get all other users with atleast one other subreddit in common\n",
        "        other_users_id = get_ids_of_users_with_common_subreddits(user_id, users, used_subreddits)\n",
        "        for other_user_id in other_users_id:\n",
        "            # Save all UNIQUE common subreddits as edge property if constraints are satisfied\n",
        "            common_subreddits = get_common_subreddits(user_id, other_user_id, used_subreddits)\n",
        "            common_subreddits = list(set(common_subreddits))\n",
        "            # Remove 'from_subreddit' as common subreddit.\n",
        "            # TODO: Should we remove biden?\n",
        "            common_subreddits = list(filter(lambda e: e not in from_subreddits[user_id], common_subreddits))\n",
        "\n",
        "            if len(common_subreddits) >= n_required_subreddits:\n",
        "                G.add_edge(users[user_id], users[other_user_id], common_subreddits=(common_subreddits), \n",
        "                           weight=len(common_subreddits))\n",
        "    return G\n",
        "\n",
        "\n",
        "# Create graph\n",
        "G = create_graph(users, used_subreddits, from_subreddits, n_required_subreddits=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vv1_ioY64Qwv"
      },
      "source": [
        "TODO: \n",
        "- Present basic NETWORK stats we got from Project A (#Edges, #nodes, avg/min/max degree)\n",
        "- Plot the network with (possibly with current classification = from_subreddit)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-vpEwGrYnbA"
      },
      "source": [
        "## 3.2 Extracting networks of interest and classifying users"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mgMRWJNZr-T"
      },
      "source": [
        "### 3.2.1 Extracting the \"backbone\" of the user network\n",
        "- Motive: \"As we saw from introduction - weighted is very dense... Might be able to extract to more informative!\" \n",
        "- Tools: \"Works by applying disperse filters, defined by \"...\n",
        "- Results: \"Resulting network is...\" (#Edges, #nodes, avg/min/max degree) + PLOT\n",
        "- Discussion: \" Will be used as comparison to weighted, to see which one gives more information\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jluN_r-JZ9fD"
      },
      "source": [
        "### 3.2.2 Classifying users with community Detection and sentiment analysis\n",
        "- Motive: \"Classifying users by from_subreddit is not necessarily optimal.\n",
        "- Tools: Three compared partitions: from_subreddit, Louvain and sentiment in comment. Modularity. Plots\n",
        "- Results: Modularity=... Plots=... #Links_Across_partition=..., MORE to decide the better partition!!?\n",
        "- Discussion: From X and Y we find __ as the best partitioning for representing each candidates' supporters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aYiNLPMZ9vr"
      },
      "source": [
        "### TBD: 3.2.3 Detecting communities with the bipartite network? ONLY MAYBE!\n",
        "- Motive: \"Bipartite networks might contain additional information, which is discarded in the projection\n",
        "- Tools: \"Explain how community detection works\"...\n",
        "- Results: \"We saw a lot more!!\" or \"revealed nothing...\"\n",
        "- Discussion: \"Probably because...\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvM9MeznY0_U"
      },
      "source": [
        "## 3.3 Comparing candidate sub-networks (of best partitioning)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6P0QHXNHafM4"
      },
      "source": [
        "### 3.3.1 Simple Network Statistics for candidate sub-networks\n",
        "- Motive: \"To compare the two networks in terms of simple statistics\"\n",
        "- Tools: #Nodes, #Edges, Degrees, densities, median, mode, \n",
        "- Results: \"compute them...\"\n",
        "- Discussion: \"This could mean that... \"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNSc85poalnK"
      },
      "source": [
        "### 3.3.2 Degree Distributions and the Network types\n",
        "- Motive: \"To understand the characteristics of our networks... Does our network follow power-law? Which could mean...\"\n",
        "- Tools: explain theory...\n",
        "- Results\n",
        "- Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yc5vt1ZsasVZ"
      },
      "source": [
        "### 3.3.3 Advanced statistics (maybe this should be 3 seperate bullets)\n",
        "- Motive: \"Which supporters are more diverse in interests? which are etc...\n",
        "- Tools: Clustering, Shortest paths and centralities in sub-networks?\n",
        "- Results\n",
        "- Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uP9TizGuay43"
      },
      "source": [
        "### 3.3.4 Community detection wihin partitions\n",
        "- Motive: \"Investigate if any communities within Biden/trump lair\"\n",
        "- Tools: Louvain\n",
        "- Results\n",
        "- Dicussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMXEh92ha3_F"
      },
      "source": [
        "## 3.4 Comparing text/comments of candidates' supporters/subreddit forum users "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8SyyqKpbnap"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWTCXdaLbUN8"
      },
      "source": [
        "### 3.4.1 Natural Language Processing\n",
        "- Motive: Is one community more eloquent? Does either community have more catch-phrases? Typical words?\n",
        "- Tools: Lexical diversity, collocations, TFTR + wordclouds\n",
        "- Results\n",
        "- Discussion\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Vi3lYFYbfvk"
      },
      "source": [
        "### 3.4.2 Sentiment analysis\n",
        "- Motive: Is one candidate´s supporters more positive than the other's?\n",
        "- Tools: Sentiment analysis of comments\n",
        "- Results\n",
        "- Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ck5dlYnLVNkv"
      },
      "source": [
        "# 4 Discussion. Think critically about your creation\n",
        "- What went well?,\n",
        "- What is still missing? What could be improved?, Why?\n",
        "  - Improvements: Maybe also try to incooporate how *often* the users have commented on the same subreddit in link weights."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khF8pi-_Zbeu"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kf4nX63WVdeX"
      },
      "source": [
        "# 5 Contributions. Who did what?\n",
        "- You should write (just briefly) which group member was the main responsible for which elements of the assignment. (I want you guys to understand every part of the assignment, but usually there is someone who took lead role on certain portions of the work. That’s what you should explain).\n",
        "\n",
        "- It is not OK simply to write \"All group members contributed equally\".\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ko2BgVOeVYHZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}